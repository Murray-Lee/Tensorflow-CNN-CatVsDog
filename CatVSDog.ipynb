{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 28, 28, 1)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "#import image\n",
    "images = []\n",
    "\n",
    "for file_name in glob.glob('/Users/murray/Desktop/catdog/preprograss12/cat*.jpg'):\n",
    "    im = mpimg.imread(file_name)\n",
    "    im = im/255.0\n",
    "    im = im[:,:, np.newaxis]\n",
    "    images.append(im)\n",
    "    \n",
    "for file_name in glob.glob('/Users/murray/Desktop/catdog/preprograss12/dog*.jpg'):\n",
    "    im = mpimg.imread(file_name)\n",
    "    im = im/255.0\n",
    "    im = im[:,:, np.newaxis]\n",
    "    images.append(im)\n",
    "\n",
    "labels = []\n",
    "cat = [1, 0]\n",
    "dog = [0, 1]\n",
    "\n",
    "for i in range(12500):\n",
    "    labels.append(cat)\n",
    "\n",
    "for i in range(12500):\n",
    "    labels.append(dog)\n",
    "  \n",
    "\n",
    "Input = np.array(images)\n",
    "Labels = np.array(labels)\n",
    "\n",
    "print (Input.shape)\n",
    "print (Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"/Users/murray/Desktop/catdog/Input1.npy\",Input)\n",
    "np.save(\"/Users/murray/Desktop/catdog/Labels1.npy\",Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 28, 28, 1)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "Input = np.load(\"/Users/murray/Desktop/catdog/Input1.npy\")\n",
    "Labels = np.load(\"/Users/murray/Desktop/catdog/Labels1.npy\")\n",
    "print(Input.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.03137255]\n",
      "  [ 0.02745098]\n",
      "  [ 0.03529412]\n",
      "  [ 0.02745098]\n",
      "  [ 0.03529412]\n",
      "  [ 0.56862745]\n",
      "  [ 0.89019608]\n",
      "  [ 0.03921569]\n",
      "  [ 0.03137255]\n",
      "  [ 0.02745098]\n",
      "  [ 0.03529412]\n",
      "  [ 0.17647059]\n",
      "  [ 0.64705882]\n",
      "  [ 0.03529412]\n",
      "  [ 0.04705882]\n",
      "  [ 0.04313725]\n",
      "  [ 0.04313725]\n",
      "  [ 0.05098039]\n",
      "  [ 0.07843137]\n",
      "  [ 0.11764706]\n",
      "  [ 0.19607843]\n",
      "  [ 0.21960784]\n",
      "  [ 0.26666667]\n",
      "  [ 0.2745098 ]\n",
      "  [ 0.21960784]\n",
      "  [ 0.28627451]\n",
      "  [ 0.02352941]\n",
      "  [ 0.03137255]]\n",
      "\n",
      " [[ 0.02745098]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03921569]\n",
      "  [ 0.01960784]\n",
      "  [ 0.02745098]\n",
      "  [ 0.65882353]\n",
      "  [ 0.60392157]\n",
      "  [ 0.        ]\n",
      "  [ 0.12941176]\n",
      "  [ 0.14901961]\n",
      "  [ 0.01960784]\n",
      "  [ 0.44705882]\n",
      "  [ 0.54509804]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03529412]\n",
      "  [ 0.04705882]\n",
      "  [ 0.05490196]\n",
      "  [ 0.08235294]\n",
      "  [ 0.12156863]\n",
      "  [ 0.2       ]\n",
      "  [ 0.22745098]\n",
      "  [ 0.2745098 ]\n",
      "  [ 0.28627451]\n",
      "  [ 0.28235294]\n",
      "  [ 0.33333333]\n",
      "  [ 0.03921569]\n",
      "  [ 0.03137255]]\n",
      "\n",
      " [[ 0.03921569]\n",
      "  [ 0.03137255]\n",
      "  [ 0.02352941]\n",
      "  [ 0.03529412]\n",
      "  [ 0.04705882]\n",
      "  [ 0.6745098 ]\n",
      "  [ 0.75686275]\n",
      "  [ 0.60784314]\n",
      "  [ 0.16862745]\n",
      "  [ 0.27058824]\n",
      "  [ 0.44705882]\n",
      "  [ 0.59215686]\n",
      "  [ 0.79607843]\n",
      "  [ 0.02745098]\n",
      "  [ 0.04705882]\n",
      "  [ 0.03137255]\n",
      "  [ 0.04313725]\n",
      "  [ 0.05490196]\n",
      "  [ 0.08235294]\n",
      "  [ 0.12156863]\n",
      "  [ 0.20784314]\n",
      "  [ 0.23137255]\n",
      "  [ 0.28235294]\n",
      "  [ 0.29803922]\n",
      "  [ 0.29411765]\n",
      "  [ 0.3372549 ]\n",
      "  [ 0.02745098]\n",
      "  [ 0.01960784]]\n",
      "\n",
      " [[ 0.02745098]\n",
      "  [ 0.02745098]\n",
      "  [ 0.01568627]\n",
      "  [ 0.03921569]\n",
      "  [ 0.01960784]\n",
      "  [ 0.08235294]\n",
      "  [ 0.81176471]\n",
      "  [ 0.52156863]\n",
      "  [ 0.56470588]\n",
      "  [ 0.66666667]\n",
      "  [ 0.44705882]\n",
      "  [ 0.57254902]\n",
      "  [ 0.09803922]\n",
      "  [ 0.04313725]\n",
      "  [ 0.02745098]\n",
      "  [ 0.04313725]\n",
      "  [ 0.04313725]\n",
      "  [ 0.05490196]\n",
      "  [ 0.08235294]\n",
      "  [ 0.1254902 ]\n",
      "  [ 0.21568627]\n",
      "  [ 0.24313725]\n",
      "  [ 0.29019608]\n",
      "  [ 0.31764706]\n",
      "  [ 0.32941176]\n",
      "  [ 0.36862745]\n",
      "  [ 0.04313725]\n",
      "  [ 0.03921569]]\n",
      "\n",
      " [[ 0.02745098]\n",
      "  [ 0.03137255]\n",
      "  [ 0.05098039]\n",
      "  [ 0.02745098]\n",
      "  [ 0.02745098]\n",
      "  [ 0.03529412]\n",
      "  [ 0.52156863]\n",
      "  [ 0.88235294]\n",
      "  [ 0.84705882]\n",
      "  [ 0.9372549 ]\n",
      "  [ 0.99607843]\n",
      "  [ 0.61568627]\n",
      "  [ 0.08235294]\n",
      "  [ 0.02352941]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03921569]\n",
      "  [ 0.04313725]\n",
      "  [ 0.05882353]\n",
      "  [ 0.08627451]\n",
      "  [ 0.13333333]\n",
      "  [ 0.23137255]\n",
      "  [ 0.25882353]\n",
      "  [ 0.30588235]\n",
      "  [ 0.3372549 ]\n",
      "  [ 0.34509804]\n",
      "  [ 0.38039216]\n",
      "  [ 0.02745098]\n",
      "  [ 0.01960784]]\n",
      "\n",
      " [[ 0.03137255]\n",
      "  [ 0.03137255]\n",
      "  [ 0.01568627]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03137255]\n",
      "  [ 0.02745098]\n",
      "  [ 0.44705882]\n",
      "  [ 0.97647059]\n",
      "  [ 0.71372549]\n",
      "  [ 0.91372549]\n",
      "  [ 0.74117647]\n",
      "  [ 0.73333333]\n",
      "  [ 0.09411765]\n",
      "  [ 0.03137255]\n",
      "  [ 0.02352941]\n",
      "  [ 0.04705882]\n",
      "  [ 0.04705882]\n",
      "  [ 0.0627451 ]\n",
      "  [ 0.08627451]\n",
      "  [ 0.1372549 ]\n",
      "  [ 0.24313725]\n",
      "  [ 0.26666667]\n",
      "  [ 0.30980392]\n",
      "  [ 0.34509804]\n",
      "  [ 0.36078431]\n",
      "  [ 0.40392157]\n",
      "  [ 0.03921569]\n",
      "  [ 0.03921569]]\n",
      "\n",
      " [[ 0.03529412]\n",
      "  [ 0.01960784]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03921569]\n",
      "  [ 0.01568627]\n",
      "  [ 0.63921569]\n",
      "  [ 0.70980392]\n",
      "  [ 0.82745098]\n",
      "  [ 0.83529412]\n",
      "  [ 0.62745098]\n",
      "  [ 0.61568627]\n",
      "  [ 0.08235294]\n",
      "  [ 0.01960784]\n",
      "  [ 0.04313725]\n",
      "  [ 0.05490196]\n",
      "  [ 0.04705882]\n",
      "  [ 0.06666667]\n",
      "  [ 0.08627451]\n",
      "  [ 0.1372549 ]\n",
      "  [ 0.24705882]\n",
      "  [ 0.27058824]\n",
      "  [ 0.30980392]\n",
      "  [ 0.34117647]\n",
      "  [ 0.34901961]\n",
      "  [ 0.39215686]\n",
      "  [ 0.01960784]\n",
      "  [ 0.03137255]]\n",
      "\n",
      " [[ 0.02745098]\n",
      "  [ 0.03529412]\n",
      "  [ 0.04313725]\n",
      "  [ 0.02352941]\n",
      "  [ 0.01960784]\n",
      "  [ 0.04705882]\n",
      "  [ 0.6       ]\n",
      "  [ 0.89803922]\n",
      "  [ 0.8745098 ]\n",
      "  [ 0.99215686]\n",
      "  [ 0.90196078]\n",
      "  [ 0.56470588]\n",
      "  [ 0.1372549 ]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03529412]\n",
      "  [ 0.05098039]\n",
      "  [ 0.05490196]\n",
      "  [ 0.07058824]\n",
      "  [ 0.09019608]\n",
      "  [ 0.14117647]\n",
      "  [ 0.25490196]\n",
      "  [ 0.2745098 ]\n",
      "  [ 0.30980392]\n",
      "  [ 0.34117647]\n",
      "  [ 0.39607843]\n",
      "  [ 0.42745098]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03137255]]\n",
      "\n",
      " [[ 0.03529412]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03529412]\n",
      "  [ 0.02352941]\n",
      "  [ 0.03529412]\n",
      "  [ 0.8745098 ]\n",
      "  [ 0.8745098 ]\n",
      "  [ 0.95294118]\n",
      "  [ 1.        ]\n",
      "  [ 0.58823529]\n",
      "  [ 0.79215686]\n",
      "  [ 0.0745098 ]\n",
      "  [ 0.01960784]\n",
      "  [ 0.02745098]\n",
      "  [ 0.05882353]\n",
      "  [ 0.05490196]\n",
      "  [ 0.09019608]\n",
      "  [ 0.10588235]\n",
      "  [ 0.15294118]\n",
      "  [ 0.2627451 ]\n",
      "  [ 0.28627451]\n",
      "  [ 0.33333333]\n",
      "  [ 0.32156863]\n",
      "  [ 0.39215686]\n",
      "  [ 0.38823529]\n",
      "  [ 0.03921569]\n",
      "  [ 0.01176471]]\n",
      "\n",
      " [[ 0.03137255]\n",
      "  [ 0.01960784]\n",
      "  [ 0.04705882]\n",
      "  [ 0.02745098]\n",
      "  [ 0.03529412]\n",
      "  [ 0.00392157]\n",
      "  [ 0.55686275]\n",
      "  [ 0.76862745]\n",
      "  [ 0.83921569]\n",
      "  [ 0.67058824]\n",
      "  [ 0.67058824]\n",
      "  [ 0.88627451]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03529412]\n",
      "  [ 0.04705882]\n",
      "  [ 0.01568627]\n",
      "  [ 0.05098039]\n",
      "  [ 0.02745098]\n",
      "  [ 0.01960784]\n",
      "  [ 0.08235294]\n",
      "  [ 0.2745098 ]\n",
      "  [ 0.30196078]\n",
      "  [ 0.30588235]\n",
      "  [ 0.35686275]\n",
      "  [ 0.4       ]\n",
      "  [ 0.45098039]\n",
      "  [ 0.00392157]\n",
      "  [ 0.04705882]]\n",
      "\n",
      " [[ 0.03137255]\n",
      "  [ 0.03529412]\n",
      "  [ 0.02745098]\n",
      "  [ 0.03529412]\n",
      "  [ 0.01960784]\n",
      "  [ 0.05098039]\n",
      "  [ 0.71764706]\n",
      "  [ 0.87058824]\n",
      "  [ 0.79215686]\n",
      "  [ 0.76470588]\n",
      "  [ 0.90196078]\n",
      "  [ 0.80392157]\n",
      "  [ 0.11372549]\n",
      "  [ 0.04313725]\n",
      "  [ 0.02745098]\n",
      "  [ 0.04313725]\n",
      "  [ 0.01568627]\n",
      "  [ 0.04705882]\n",
      "  [ 0.05490196]\n",
      "  [ 0.10980392]\n",
      "  [ 0.20784314]\n",
      "  [ 0.03921569]\n",
      "  [ 0.02745098]\n",
      "  [ 0.01176471]\n",
      "  [ 0.01960784]\n",
      "  [ 0.43921569]\n",
      "  [ 0.03921569]\n",
      "  [ 0.03529412]]\n",
      "\n",
      " [[ 0.03137255]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03137255]\n",
      "  [ 0.01568627]\n",
      "  [ 0.02745098]\n",
      "  [ 0.04313725]\n",
      "  [ 0.8       ]\n",
      "  [ 0.84313725]\n",
      "  [ 0.78431373]\n",
      "  [ 1.        ]\n",
      "  [ 0.93333333]\n",
      "  [ 0.55686275]\n",
      "  [ 0.24313725]\n",
      "  [ 0.09019608]\n",
      "  [ 0.01568627]\n",
      "  [ 0.02745098]\n",
      "  [ 0.05098039]\n",
      "  [ 0.03529412]\n",
      "  [ 0.02745098]\n",
      "  [ 0.03921569]\n",
      "  [ 0.01568627]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03529412]\n",
      "  [ 0.07058824]\n",
      "  [ 0.03529412]\n",
      "  [ 0.04313725]\n",
      "  [ 0.02352941]]\n",
      "\n",
      " [[ 0.03137255]\n",
      "  [ 0.02745098]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03921569]\n",
      "  [ 0.02745098]\n",
      "  [ 0.03137255]\n",
      "  [ 0.80392157]\n",
      "  [ 0.78431373]\n",
      "  [ 0.73333333]\n",
      "  [ 0.72941176]\n",
      "  [ 0.71764706]\n",
      "  [ 0.60784314]\n",
      "  [ 0.2       ]\n",
      "  [ 0.28235294]\n",
      "  [ 0.30196078]\n",
      "  [ 0.09411765]\n",
      "  [ 0.10196078]\n",
      "  [ 0.10980392]\n",
      "  [ 0.02352941]\n",
      "  [ 0.2       ]\n",
      "  [ 0.28627451]\n",
      "  [ 0.23529412]\n",
      "  [ 0.36078431]\n",
      "  [ 0.11764706]\n",
      "  [ 0.43529412]\n",
      "  [ 0.02745098]\n",
      "  [ 0.01568627]\n",
      "  [ 0.03529412]]\n",
      "\n",
      " [[ 0.02745098]\n",
      "  [ 0.04313725]\n",
      "  [ 0.02352941]\n",
      "  [ 0.1254902 ]\n",
      "  [ 0.03137255]\n",
      "  [ 0.04705882]\n",
      "  [ 0.91764706]\n",
      "  [ 0.8745098 ]\n",
      "  [ 0.81176471]\n",
      "  [ 0.74901961]\n",
      "  [ 0.69411765]\n",
      "  [ 0.62352941]\n",
      "  [ 0.3254902 ]\n",
      "  [ 0.41568627]\n",
      "  [ 0.24313725]\n",
      "  [ 0.15686275]\n",
      "  [ 0.11372549]\n",
      "  [ 0.1254902 ]\n",
      "  [ 0.03921569]\n",
      "  [ 0.19607843]\n",
      "  [ 0.2745098 ]\n",
      "  [ 0.27058824]\n",
      "  [ 0.32941176]\n",
      "  [ 0.05098039]\n",
      "  [ 0.41176471]\n",
      "  [ 0.03921569]\n",
      "  [ 0.03529412]\n",
      "  [ 0.02352941]]\n",
      "\n",
      " [[ 0.02745098]\n",
      "  [ 0.03529412]\n",
      "  [ 0.02745098]\n",
      "  [ 0.12156863]\n",
      "  [ 0.04705882]\n",
      "  [ 0.01960784]\n",
      "  [ 0.85490196]\n",
      "  [ 0.83529412]\n",
      "  [ 0.85882353]\n",
      "  [ 0.83921569]\n",
      "  [ 0.78823529]\n",
      "  [ 0.74901961]\n",
      "  [ 0.32156863]\n",
      "  [ 0.60392157]\n",
      "  [ 0.49803922]\n",
      "  [ 0.44705882]\n",
      "  [ 0.02352941]\n",
      "  [ 0.09411765]\n",
      "  [ 0.0627451 ]\n",
      "  [ 0.19607843]\n",
      "  [ 0.28235294]\n",
      "  [ 0.2627451 ]\n",
      "  [ 0.35294118]\n",
      "  [ 0.03529412]\n",
      "  [ 0.38431373]\n",
      "  [ 0.07058824]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03137255]]\n",
      "\n",
      " [[ 0.02745098]\n",
      "  [ 0.03529412]\n",
      "  [ 0.02352941]\n",
      "  [ 0.01176471]\n",
      "  [ 0.01960784]\n",
      "  [ 0.02745098]\n",
      "  [ 0.89803922]\n",
      "  [ 0.75294118]\n",
      "  [ 0.60392157]\n",
      "  [ 0.63921569]\n",
      "  [ 0.64705882]\n",
      "  [ 0.61568627]\n",
      "  [ 0.36862745]\n",
      "  [ 0.62745098]\n",
      "  [ 0.56078431]\n",
      "  [ 0.21960784]\n",
      "  [ 0.28627451]\n",
      "  [ 0.09411765]\n",
      "  [ 0.05490196]\n",
      "  [ 0.20784314]\n",
      "  [ 0.25490196]\n",
      "  [ 0.30980392]\n",
      "  [ 0.34117647]\n",
      "  [ 0.22745098]\n",
      "  [ 0.41568627]\n",
      "  [ 0.34901961]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03921569]]\n",
      "\n",
      " [[ 0.03137255]\n",
      "  [ 0.03529412]\n",
      "  [ 0.01568627]\n",
      "  [ 0.05490196]\n",
      "  [ 0.02745098]\n",
      "  [ 0.02745098]\n",
      "  [ 0.75294118]\n",
      "  [ 0.75294118]\n",
      "  [ 0.74509804]\n",
      "  [ 0.54901961]\n",
      "  [ 0.60784314]\n",
      "  [ 0.75686275]\n",
      "  [ 0.2       ]\n",
      "  [ 0.51372549]\n",
      "  [ 0.59607843]\n",
      "  [ 0.24705882]\n",
      "  [ 0.00784314]\n",
      "  [ 0.10196078]\n",
      "  [ 0.10980392]\n",
      "  [ 0.18431373]\n",
      "  [ 0.14901961]\n",
      "  [ 0.29411765]\n",
      "  [ 0.33333333]\n",
      "  [ 0.35294118]\n",
      "  [ 0.39215686]\n",
      "  [ 0.41176471]\n",
      "  [ 0.03137255]\n",
      "  [ 0.01176471]]\n",
      "\n",
      " [[ 0.02745098]\n",
      "  [ 0.03921569]\n",
      "  [ 0.03529412]\n",
      "  [ 0.01568627]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03137255]\n",
      "  [ 0.20784314]\n",
      "  [ 0.54901961]\n",
      "  [ 0.4745098 ]\n",
      "  [ 0.65882353]\n",
      "  [ 0.59215686]\n",
      "  [ 0.18431373]\n",
      "  [ 0.36078431]\n",
      "  [ 0.62352941]\n",
      "  [ 0.43529412]\n",
      "  [ 0.19607843]\n",
      "  [ 0.41176471]\n",
      "  [ 0.2       ]\n",
      "  [ 0.04313725]\n",
      "  [ 0.20392157]\n",
      "  [ 0.02352941]\n",
      "  [ 0.29803922]\n",
      "  [ 0.37254902]\n",
      "  [ 0.08627451]\n",
      "  [ 0.04313725]\n",
      "  [ 0.05098039]\n",
      "  [ 0.05098039]\n",
      "  [ 0.04705882]]\n",
      "\n",
      " [[ 0.02745098]\n",
      "  [ 0.02745098]\n",
      "  [ 0.02745098]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03529412]\n",
      "  [ 0.03137255]\n",
      "  [ 0.68627451]\n",
      "  [ 0.35686275]\n",
      "  [ 0.46666667]\n",
      "  [ 0.63137255]\n",
      "  [ 0.56470588]\n",
      "  [ 0.6       ]\n",
      "  [ 0.49019608]\n",
      "  [ 0.32941176]\n",
      "  [ 0.50588235]\n",
      "  [ 0.4627451 ]\n",
      "  [ 0.43529412]\n",
      "  [ 0.11372549]\n",
      "  [ 0.01568627]\n",
      "  [ 0.05490196]\n",
      "  [ 0.08627451]\n",
      "  [ 0.05098039]\n",
      "  [ 0.06666667]\n",
      "  [ 0.05882353]\n",
      "  [ 0.0627451 ]\n",
      "  [ 0.03529412]\n",
      "  [ 0.04705882]\n",
      "  [ 0.03137255]]\n",
      "\n",
      " [[ 0.03921569]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03137255]\n",
      "  [ 0.04313725]\n",
      "  [ 0.03529412]\n",
      "  [ 0.54509804]\n",
      "  [ 0.70196078]\n",
      "  [ 0.49803922]\n",
      "  [ 0.57647059]\n",
      "  [ 0.69411765]\n",
      "  [ 0.24313725]\n",
      "  [ 0.47058824]\n",
      "  [ 0.5254902 ]\n",
      "  [ 0.51372549]\n",
      "  [ 0.38039216]\n",
      "  [ 0.43921569]\n",
      "  [ 0.33333333]\n",
      "  [ 0.26666667]\n",
      "  [ 0.07058824]\n",
      "  [ 0.05882353]\n",
      "  [ 0.05882353]\n",
      "  [ 0.07058824]\n",
      "  [ 0.03921569]\n",
      "  [ 0.03529412]\n",
      "  [ 0.07058824]\n",
      "  [ 0.03529412]\n",
      "  [ 0.0627451 ]]\n",
      "\n",
      " [[ 0.09411765]\n",
      "  [ 0.12941176]\n",
      "  [ 0.12156863]\n",
      "  [ 0.08235294]\n",
      "  [ 0.10588235]\n",
      "  [ 0.09803922]\n",
      "  [ 0.74509804]\n",
      "  [ 0.04313725]\n",
      "  [ 0.57254902]\n",
      "  [ 0.28627451]\n",
      "  [ 0.63137255]\n",
      "  [ 0.57647059]\n",
      "  [ 0.34901961]\n",
      "  [ 0.29019608]\n",
      "  [ 0.26666667]\n",
      "  [ 0.4627451 ]\n",
      "  [ 0.58039216]\n",
      "  [ 0.51764706]\n",
      "  [ 0.40392157]\n",
      "  [ 0.04705882]\n",
      "  [ 0.05490196]\n",
      "  [ 0.07058824]\n",
      "  [ 0.04313725]\n",
      "  [ 0.05490196]\n",
      "  [ 0.05882353]\n",
      "  [ 0.09019608]\n",
      "  [ 0.16470588]\n",
      "  [ 0.19607843]]\n",
      "\n",
      " [[ 0.10196078]\n",
      "  [ 0.0745098 ]\n",
      "  [ 0.10980392]\n",
      "  [ 0.08627451]\n",
      "  [ 0.14901961]\n",
      "  [ 0.08627451]\n",
      "  [ 0.74901961]\n",
      "  [ 0.64705882]\n",
      "  [ 0.29803922]\n",
      "  [ 0.09411765]\n",
      "  [ 0.45882353]\n",
      "  [ 0.62745098]\n",
      "  [ 0.30588235]\n",
      "  [ 0.2745098 ]\n",
      "  [ 0.16078431]\n",
      "  [ 0.58039216]\n",
      "  [ 0.62352941]\n",
      "  [ 0.43137255]\n",
      "  [ 0.37647059]\n",
      "  [ 0.01960784]\n",
      "  [ 0.04705882]\n",
      "  [ 0.03137255]\n",
      "  [ 0.20392157]\n",
      "  [ 0.22745098]\n",
      "  [ 0.03921569]\n",
      "  [ 0.02352941]\n",
      "  [ 0.05882353]\n",
      "  [ 0.06666667]]\n",
      "\n",
      " [[ 0.07058824]\n",
      "  [ 0.05490196]\n",
      "  [ 0.0627451 ]\n",
      "  [ 0.10980392]\n",
      "  [ 0.09411765]\n",
      "  [ 0.1372549 ]\n",
      "  [ 0.87843137]\n",
      "  [ 0.45098039]\n",
      "  [ 0.03921569]\n",
      "  [ 0.09803922]\n",
      "  [ 0.76470588]\n",
      "  [ 0.37647059]\n",
      "  [ 0.23921569]\n",
      "  [ 0.61960784]\n",
      "  [ 0.47058824]\n",
      "  [ 0.57647059]\n",
      "  [ 0.60392157]\n",
      "  [ 0.45882353]\n",
      "  [ 0.34509804]\n",
      "  [ 0.03137255]\n",
      "  [ 0.03921569]\n",
      "  [ 0.05490196]\n",
      "  [ 0.03921569]\n",
      "  [ 0.08627451]\n",
      "  [ 0.0745098 ]\n",
      "  [ 0.09411765]\n",
      "  [ 0.0745098 ]\n",
      "  [ 0.10196078]]\n",
      "\n",
      " [[ 0.13333333]\n",
      "  [ 0.07843137]\n",
      "  [ 0.08627451]\n",
      "  [ 0.07843137]\n",
      "  [ 0.08627451]\n",
      "  [ 0.10196078]\n",
      "  [ 0.79607843]\n",
      "  [ 0.21568627]\n",
      "  [ 0.09411765]\n",
      "  [ 0.11372549]\n",
      "  [ 0.54117647]\n",
      "  [ 0.40392157]\n",
      "  [ 0.24313725]\n",
      "  [ 0.60392157]\n",
      "  [ 0.50196078]\n",
      "  [ 0.56078431]\n",
      "  [ 0.58431373]\n",
      "  [ 0.40392157]\n",
      "  [ 0.18039216]\n",
      "  [ 0.00392157]\n",
      "  [ 0.11372549]\n",
      "  [ 0.0627451 ]\n",
      "  [ 0.07058824]\n",
      "  [ 0.08627451]\n",
      "  [ 0.09019608]\n",
      "  [ 0.09019608]\n",
      "  [ 0.09411765]\n",
      "  [ 0.10196078]]\n",
      "\n",
      " [[ 0.12941176]\n",
      "  [ 0.09019608]\n",
      "  [ 0.08235294]\n",
      "  [ 0.0745098 ]\n",
      "  [ 0.07843137]\n",
      "  [ 0.14117647]\n",
      "  [ 0.79607843]\n",
      "  [ 0.41568627]\n",
      "  [ 0.09803922]\n",
      "  [ 0.08235294]\n",
      "  [ 0.65098039]\n",
      "  [ 0.37254902]\n",
      "  [ 0.10196078]\n",
      "  [ 0.09803922]\n",
      "  [ 0.58823529]\n",
      "  [ 0.28235294]\n",
      "  [ 0.44705882]\n",
      "  [ 0.3254902 ]\n",
      "  [ 0.03529412]\n",
      "  [ 0.11764706]\n",
      "  [ 0.03921569]\n",
      "  [ 0.12156863]\n",
      "  [ 0.11372549]\n",
      "  [ 0.10588235]\n",
      "  [ 0.10980392]\n",
      "  [ 0.10980392]\n",
      "  [ 0.10980392]\n",
      "  [ 0.10588235]]\n",
      "\n",
      " [[ 0.11764706]\n",
      "  [ 0.10980392]\n",
      "  [ 0.0745098 ]\n",
      "  [ 0.0745098 ]\n",
      "  [ 0.09803922]\n",
      "  [ 0.54509804]\n",
      "  [ 0.70980392]\n",
      "  [ 0.10588235]\n",
      "  [ 0.0627451 ]\n",
      "  [ 0.07843137]\n",
      "  [ 0.54509804]\n",
      "  [ 0.47843137]\n",
      "  [ 0.09019608]\n",
      "  [ 0.09411765]\n",
      "  [ 0.12156863]\n",
      "  [ 0.29803922]\n",
      "  [ 0.13333333]\n",
      "  [ 0.10980392]\n",
      "  [ 0.15686275]\n",
      "  [ 0.14509804]\n",
      "  [ 0.1254902 ]\n",
      "  [ 0.10196078]\n",
      "  [ 0.10980392]\n",
      "  [ 0.11764706]\n",
      "  [ 0.11372549]\n",
      "  [ 0.10980392]\n",
      "  [ 0.10196078]\n",
      "  [ 0.09803922]]\n",
      "\n",
      " [[ 0.13333333]\n",
      "  [ 0.10980392]\n",
      "  [ 0.09019608]\n",
      "  [ 0.07058824]\n",
      "  [ 0.03529412]\n",
      "  [ 0.65882353]\n",
      "  [ 0.38039216]\n",
      "  [ 0.05098039]\n",
      "  [ 0.13333333]\n",
      "  [ 0.13333333]\n",
      "  [ 0.66666667]\n",
      "  [ 0.46666667]\n",
      "  [ 0.07843137]\n",
      "  [ 0.10980392]\n",
      "  [ 0.13333333]\n",
      "  [ 0.16470588]\n",
      "  [ 0.11372549]\n",
      "  [ 0.2       ]\n",
      "  [ 0.17647059]\n",
      "  [ 0.16470588]\n",
      "  [ 0.18823529]\n",
      "  [ 0.12941176]\n",
      "  [ 0.09411765]\n",
      "  [ 0.10588235]\n",
      "  [ 0.10588235]\n",
      "  [ 0.09803922]\n",
      "  [ 0.08627451]\n",
      "  [ 0.0745098 ]]\n",
      "\n",
      " [[ 0.12156863]\n",
      "  [ 0.11372549]\n",
      "  [ 0.10980392]\n",
      "  [ 0.10588235]\n",
      "  [ 0.10588235]\n",
      "  [ 0.21960784]\n",
      "  [ 0.11764706]\n",
      "  [ 0.13333333]\n",
      "  [ 0.10588235]\n",
      "  [ 0.10980392]\n",
      "  [ 0.11372549]\n",
      "  [ 0.10196078]\n",
      "  [ 0.10588235]\n",
      "  [ 0.16862745]\n",
      "  [ 0.14509804]\n",
      "  [ 0.1372549 ]\n",
      "  [ 0.18039216]\n",
      "  [ 0.09411765]\n",
      "  [ 0.21176471]\n",
      "  [ 0.15294118]\n",
      "  [ 0.10196078]\n",
      "  [ 0.17254902]\n",
      "  [ 0.11372549]\n",
      "  [ 0.09019608]\n",
      "  [ 0.09411765]\n",
      "  [ 0.08235294]\n",
      "  [ 0.06666667]\n",
      "  [ 0.05882353]]]\n"
     ]
    }
   ],
   "source": [
    "print(Input[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(25000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Input[1].shape)\n",
    "print(Input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 500\n",
    "batch_size = 256\n",
    "display_step = 10\n",
    "numOfEpoch = 100\n",
    "\n",
    "# Network Parameters\n",
    "num_classes = 2 \n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, 28,28,1])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.get_variable(\"Wc1\", shape=[5,5,1,32], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.get_variable(\"Wc2\", shape=[5, 5, 32, 64], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.get_variable(\"Wd1\", shape=[7*7*64,1024], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.get_variable(\"Wout\", shape=[1024, num_classes],initializer=tf.contrib.layers.xavier_initializer())\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_op)\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Saver use to store the model\n",
    "saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 1, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 2, Minibatch Loss= 0.6925, Training Accuracy= 0.500\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 3, Minibatch Loss= 0.6922, Training Accuracy= 0.526\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 4, Minibatch Loss= 0.6882, Training Accuracy= 0.547\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 5, Minibatch Loss= 0.6862, Training Accuracy= 0.554\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 6, Minibatch Loss= 0.6836, Training Accuracy= 0.548\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 7, Minibatch Loss= 0.6722, Training Accuracy= 0.583\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 8, Minibatch Loss= 0.6597, Training Accuracy= 0.602\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 9, Minibatch Loss= 0.6758, Training Accuracy= 0.587\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 10, Minibatch Loss= 0.6381, Training Accuracy= 0.622\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 11, Minibatch Loss= 0.6324, Training Accuracy= 0.635\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 12, Minibatch Loss= 0.6124, Training Accuracy= 0.661\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 13, Minibatch Loss= 0.6001, Training Accuracy= 0.673\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 14, Minibatch Loss= 0.5916, Training Accuracy= 0.681\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 15, Minibatch Loss= 0.5992, Training Accuracy= 0.668\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 16, Minibatch Loss= 0.5887, Training Accuracy= 0.687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 17, Minibatch Loss= 0.5711, Training Accuracy= 0.703\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 18, Minibatch Loss= 0.5717, Training Accuracy= 0.698\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 19, Minibatch Loss= 0.5624, Training Accuracy= 0.709\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 20, Minibatch Loss= 0.5726, Training Accuracy= 0.699\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 21, Minibatch Loss= 0.5860, Training Accuracy= 0.692\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 22, Minibatch Loss= 0.5511, Training Accuracy= 0.716\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 23, Minibatch Loss= 0.5580, Training Accuracy= 0.706\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 24, Minibatch Loss= 0.5385, Training Accuracy= 0.726\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 25, Minibatch Loss= 0.5384, Training Accuracy= 0.729\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 26, Minibatch Loss= 0.5344, Training Accuracy= 0.730\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 27, Minibatch Loss= 0.5359, Training Accuracy= 0.732\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 28, Minibatch Loss= 0.5326, Training Accuracy= 0.723\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 29, Minibatch Loss= 0.5176, Training Accuracy= 0.733\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 30, Minibatch Loss= 0.5089, Training Accuracy= 0.750\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 31, Minibatch Loss= 0.5322, Training Accuracy= 0.741\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 32, Minibatch Loss= 0.4811, Training Accuracy= 0.772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 33, Minibatch Loss= 0.4597, Training Accuracy= 0.786\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 34, Minibatch Loss= 0.4941, Training Accuracy= 0.764\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 35, Minibatch Loss= 0.4591, Training Accuracy= 0.783\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 36, Minibatch Loss= 0.4571, Training Accuracy= 0.781\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 37, Minibatch Loss= 0.4321, Training Accuracy= 0.798\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 38, Minibatch Loss= 0.4255, Training Accuracy= 0.802\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 39, Minibatch Loss= 0.4211, Training Accuracy= 0.805\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 40, Minibatch Loss= 0.4078, Training Accuracy= 0.811\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 41, Minibatch Loss= 0.4040, Training Accuracy= 0.809\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 42, Minibatch Loss= 0.4255, Training Accuracy= 0.799\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 43, Minibatch Loss= 0.3663, Training Accuracy= 0.846\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 44, Minibatch Loss= 0.3631, Training Accuracy= 0.831\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 45, Minibatch Loss= 0.3406, Training Accuracy= 0.858\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 46, Minibatch Loss= 0.3462, Training Accuracy= 0.850\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 47, Minibatch Loss= 0.3197, Training Accuracy= 0.855\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 48, Minibatch Loss= 0.2910, Training Accuracy= 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 49, Minibatch Loss= 0.2869, Training Accuracy= 0.894\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 50, Minibatch Loss= 0.2746, Training Accuracy= 0.894\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 51, Minibatch Loss= 0.2673, Training Accuracy= 0.889\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 52, Minibatch Loss= 0.2378, Training Accuracy= 0.909\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 53, Minibatch Loss= 0.2255, Training Accuracy= 0.917\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 54, Minibatch Loss= 0.2152, Training Accuracy= 0.928\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 55, Minibatch Loss= 0.1994, Training Accuracy= 0.926\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 56, Minibatch Loss= 0.1823, Training Accuracy= 0.933\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 57, Minibatch Loss= 0.1813, Training Accuracy= 0.931\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 58, Minibatch Loss= 0.1679, Training Accuracy= 0.940\n",
      "The step is in 0 step\n",
      "The step is in 1280 step\n",
      "The step is in 2560 step\n",
      "The step is in 3840 step\n",
      "The step is in 5120 step\n",
      "The step is in 6400 step\n",
      "The step is in 7680 step\n",
      "The step is in 8960 step\n",
      "The step is in 10240 step\n",
      "The step is in 11520 step\n",
      "The step is in 12800 step\n",
      "The step is in 14080 step\n",
      "The step is in 15360 step\n",
      "The step is in 16640 step\n",
      "The step is in 17920 step\n",
      "The step is in 19200 step\n",
      "The step is in 20480 step\n",
      "The step is in 21760 step\n",
      "Step 59, Minibatch Loss= 0.1491, Training Accuracy= 0.950\n",
      "The step is in 0 step\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(1, numOfEpoch):\n",
    "        train_x, val_x, train_y, val_y = train_test_split(Input, Labels, test_size = 0.1)   \n",
    "        \n",
    "        for i in range(0, len(train_x), batch_size):\n",
    "            trainLoss, _ = sess.run([loss_op, optimizer], feed_dict = {\n",
    "                X: train_x[i: i+batch_size],\n",
    "                Y: train_y[i: i+batch_size],\n",
    "                keep_prob: dropout\n",
    "            })\n",
    "            if i % 5 == 0:\n",
    "                print(\"The step is in \"+ str(i)+ \" step\")\n",
    "        \n",
    "        valAcc, valLoss = sess.run([accuracy, loss_op], feed_dict={\n",
    "            X: val_x,\n",
    "            Y: val_y,\n",
    "            keep_prob: 1.0})\n",
    "             \n",
    "        print(\"Step \" + str(epoch) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(valLoss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(valAcc))\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    saver.save(sess, \"../model.ckpt\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()  \n",
    "  \n",
    "with tf.Session() as sess:  \n",
    "    saver.restore(sess, \"../model.ckpt\") \n",
    "    loss, acc = sess.run([loss_op, accuracy], feed_dict={X: Input[0:10000], Y: Labels[0:10000], keep_prob: 1.0})\n",
    "    print(\"loss is :\")\n",
    "    print(loss)\n",
    "    print(\"accuracy is:\")\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()  \n",
    "  \n",
    "with tf.Session() as sess:  \n",
    "    saver.restore(sess, \"../model.ckpt\")\n",
    "    preds = sess.run([prediction],feed_dict={X: Input[0:10], Y: Labels[0:10], keep_prob: 1.0})\n",
    "    print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showImage(n):\n",
    "    image = Input[n].reshape([28,28])\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMvX//6rIs+0W84QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12cade650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImage(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nViNVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d139350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImage(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+JD7VMMpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d2e6f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImage(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFyJSZH4hIuX/AEfAAwHeVcUPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d459150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImage(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
